{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Duelling Double Deep Q Learning - A simple hospital model\n",
    "\n",
    "In this example we take the previous example of Duelling Double Q Learning and add 'noisy layers' to the estimatin of advantage. Adding noise within the network is an alterantive to epsilon-greedy exploration. As the performance of the system improves the amount of noise will reduce in the network, as noise is a parameter in the network which is optimised through the normal network optimization procedure.\n",
    "\n",
    "## A simple hospital simulation model\n",
    "\n",
    "This is an example of a simple hospital bed model where a Reinforcement learning (RL) agent has to learn how to manage the bed stock:\n",
    "\n",
    "    • Default arrivals = 50/day\n",
    "    • Weekend arrival numbers are 50% average arrival numbers\n",
    "    • Weekday arrival numbers are 120% average arrival numbers\n",
    "    • Distribution of inter-arrival time is inverse exponential\n",
    "    • Average length of stay is 7 days (default)\n",
    "    • Distribution of length of stay is inverse exponential\n",
    "    • The RL agent may request a change in bed numbers once a day (default)\n",
    "    • The allowed bed change requests are -20, -10, 0, 10, 20\n",
    "    • Bed changes take 2 days to occur (default)\n",
    "    • The RL agent receives a reward at each action based on the number of free beds or number of patients without a bed\n",
    "    • The simulation is loaded with the average number of patients present\n",
    "    \n",
    "The RL agent must learn to maximise the long term reward (return). The maximum reward = 0, so the agent is learning to minimise the loss for each unoccupied bed or patient without bed.\n",
    "\n",
    "## Reinforcement learning introduction\n",
    "\n",
    "### RL involves:\n",
    "* Trial and error search\n",
    "* Receiving and maximising reward (often delayed)\n",
    "* Linking state -> action -> reward\n",
    "* Must be able to sense something of their environment\n",
    "* Involves uncertainty in sensing and linking action to reward\n",
    "* Learning -> improved choice of actions over time\n",
    "* All models find a way to balance best predicted action vs. exploration\n",
    "\n",
    "### Elements of RL\n",
    "* *Environment*: all observable and unobservable information relevant to us\n",
    "* *Observation*: sensing the environment\n",
    "* *State*: the perceived (or perceivable) environment \n",
    "* *Agent*: senses environment, decides on action, receives and monitors rewards\n",
    "* *Action*: may be discrete (e.g. turn left) or continuous (accelerator pedal)\n",
    "* *Policy* (how to link state to action; often based on probabilities)\n",
    "* *Reward signal*: aim is to accumulate maximum reward over time\n",
    "* *Value function* of a state: prediction of likely/possible long-term reward\n",
    "* *Q*: prediction of likely/possible long-term reward of an *action*\n",
    "* *Advantage*: The difference in Q between actions in a given state (sums to zero for all actions)\n",
    "* *Model* (optional): a simulation of the environment\n",
    "\n",
    "### Types of model\n",
    "\n",
    "* *Model-based*: have model of environment (e.g. a board game)\n",
    "* *Model-free*: used when environment not fully known\n",
    "* *Policy-based*: identify best policy directly\n",
    "* *Value-based*: estimate value of a decision\n",
    "* *Off-policy*: can learn from historic data from other agent\n",
    "* *On-policy*: requires active learning from current decisions\n",
    "\n",
    "\n",
    "## Duelling Deep Q Networks for Reinforcement Learning\n",
    "\n",
    "Q = The expected future rewards discounted over time. This is what we are trying to maximise.\n",
    "\n",
    "The aim is to teach a network to take the current state observations and recommend the action with greatest Q.\n",
    "\n",
    "Duelling is very similar to Double DQN, except that the policy net splits into two. One component reduces to a single value, which will model the state *value*. The other component models the *advantage*, the difference in Q between different actions (the mean value is subtracted from all values, so that the advtantage always sums to zero). These are aggregated to produce Q for each action. \n",
    "\n",
    "<img src=\"./images/duelling_dqn.png\" width=\"500\"/>\n",
    "\n",
    "Q is learned through the Bellman equation, where the Q of any state and action is the immediate reward achieved + the discounted maximum Q value (the best action taken) of next best action, where gamma is the discount rate.\n",
    "\n",
    "$$Q(s,a)=r + \\gamma.maxQ(s',a')$$\n",
    "\n",
    "## Key DQN components\n",
    "\n",
    "<img src=\"./images/dqn_components.png\" width=\"700\"/>\n",
    "\n",
    "\n",
    "## General method for Q learning:\n",
    "\n",
    "Overall aim is to create a neural network that predicts Q. Improvement comes from improved accuracy in predicting 'current' understood Q, and in revealing more about Q as knowledge is gained (some rewards only discovered after time).\n",
    "\n",
    "<img src=\"./images/dqn_process.png\" width=\"600|\"/>\n",
    "    \n",
    "Target networks are used to stabilise models, and are only updated at intervals. Changes to Q values may lead to changes in closely related states (i.e. states close to the one we are in at the time) and as the network tries to correct for errors it can become unstable and suddenly lose signficiant performance. Target networks (e.g. to assess Q) are updated only infrequently (or gradually), so do not have this instability problem.\n",
    "\n",
    "## Training networks\n",
    "\n",
    "Double DQN contains two networks. This ammendment, from simple DQN, is to decouple training of Q for current state and target Q derived from next state which are closely correlated when comparing input features.\n",
    "\n",
    "The *policy network* is used to select action (action with best predicted Q) when playing the game.\n",
    "\n",
    "When training, the predicted best *action* (best predicted Q) is taken from the *policy network*, but the *policy network* is updated using the predicted Q value of the next state from the *target network* (which is updated from the policy network less frequently). So, when training, the action is selected using Q values from the *policy network*, but the the *policy network* is updated to better predict the Q value of that action from the *target network*. The *policy network* is copied across to the *target network* every *n* steps (e.g. 1000).\n",
    "\n",
    "<img src=\"./images/dqn_training.png\" width=\"700|\"/>\n",
    "\n",
    "## Noisy layers\n",
    "Noisy layers are an alternative to epsilon-greedy exploration (here, we leave the epsilon-greedy code in the model, but set it to reduce to zero immediately after the period of fully random action choice).\n",
    "\n",
    "For every weight in the layer we have a random value that we draw from the normal distribution. This random value is used to add noise to the output. The parameters for the extent of noise for each weight, sigma, are stored within the layer and get trained as part of the standard back-propogation.\n",
    "\n",
    "A modification to normal nosiy layers is to use layers with ‘factorized gaussian noise’. This reduces the number of random numbers to be sampled (so is less computationally expensive). There are two random vectors, one with the size of the input, and the other with the size of the output. A random matrix is created by calculating the outer product of the two vectors.\n",
    "\n",
    "## References\n",
    "\n",
    "Double DQN: \n",
    "van Hasselt H, Guez A, Silver D. (2015) Deep Reinforcement Learning with Double Q-learning. arXiv:150906461 http://arxiv.org/abs/1509.06461\n",
    "\n",
    "Duelling DDQN:\n",
    "Wang Z, Schaul T, Hessel M, et al. (2016) Dueling Network Architectures for Deep Reinforcement Learning. arXiv:151106581 http://arxiv.org/abs/1511.06581\n",
    "\n",
    "Noisy networks:\n",
    "Fortunato M, Azar MG, Piot B, et al. (2019) Noisy Networks for Exploration. arXiv:170610295 http://arxiv.org/abs/1706.10295\n",
    "\n",
    "Code for the nosiy layers comes from:\n",
    "\n",
    "Lapan, M. (2020). Deep Reinforcement Learning Hands-On: Apply modern RL methods to practical problems of chatbots, robotics, discrete optimization, web automation, and more, 2nd Edition. Packt Publishing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code structure\n",
    "\n",
    "<img src=\"./images/dqn_program_structure.png\" width=\"700|\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                           1 Import packages                                  #\n",
    "################################################################################\n",
    "\n",
    "from simpy_envs.env_simple_hospital_bed_1 import HospGym\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Use a double ended queue (deque) for memory\n",
    "# When memory is full, this will replace the oldest value with the new one\n",
    "from collections import deque\n",
    "\n",
    "# Supress all warnings (e.g. deprecation warnings) for regular use\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                           2 Define model parameters                          #\n",
    "################################################################################\n",
    "\n",
    "# Set whether to display on screen (slows model)\n",
    "DISPLAY_ON_SCREEN = False\n",
    "# Discount rate of future rewards\n",
    "GAMMA = 0.95\n",
    "# Learing rate for neural network\n",
    "LEARNING_RATE = 0.0003\n",
    "# Maximum number of game steps (state, action, reward, next state) to keep\n",
    "MEMORY_SIZE = 1000000\n",
    "# Sample batch size for policy network update\n",
    "BATCH_SIZE = 3\n",
    "# Number of game steps to play before starting training (all random actions)\n",
    "REPLAY_START_SIZE = 365 * 5\n",
    "# Time step between actions\n",
    "TIME_STEP = 1\n",
    "# Number of steps between policy -> target network update\n",
    "SYNC_TARGET_STEPS = 365\n",
    "# Exploration rate (episolon) is probability of choosign a random action\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.0\n",
    "# Reduction in epsilon with each game step\n",
    "EXPLORATION_DECAY = 0.0\n",
    "# Simulation duration\n",
    "SIM_DURATION = 365\n",
    "# Training episodes\n",
    "TRAINING_EPISODES = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                 3 Define DQN (Duelling Deep Q Network) class                 #\n",
    "#                    (Used for both policy and target nets)                    #\n",
    "################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Code for nosiy layers comes from:\n",
    "\n",
    "Lapan, M. (2020). Deep Reinforcement Learning Hands-On: Apply modern RL methods \n",
    "to practical problems of chatbots, robotics, discrete optimization, \n",
    "web automation, and more, 2nd Edition. Packt Publishing.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class NoisyLinear(nn.Linear):\n",
    "    \"\"\"\n",
    "    Noisy layer for network.\n",
    "    \n",
    "    For every weight in the layer we have a random value that we draw from the\n",
    "    normal distribution.Paraemters for the noise, sigma, are stored within the\n",
    "    layer and get trained as part of the standard back-propogation.\n",
    "    \n",
    "    'register_buffer' is used to create tensors in the network that are not\n",
    "    updated during back-propogation. They are used to create normal \n",
    "    distributions to add noise (multiplied by sigma which is a paramater in the\n",
    "    network).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features,\n",
    "                 sigma_init=0.017, bias=True):\n",
    "        super(NoisyLinear, self).__init__(\n",
    "            in_features, out_features, bias=bias)\n",
    "        w = torch.full((out_features, in_features), sigma_init)\n",
    "        self.sigma_weight = nn.Parameter(w)\n",
    "        z = torch.zeros(out_features, in_features)\n",
    "        self.register_buffer(\"epsilon_weight\", z)\n",
    "        if bias:\n",
    "            w = torch.full((out_features,), sigma_init)\n",
    "            self.sigma_bias = nn.Parameter(w)\n",
    "            z = torch.zeros(out_features)\n",
    "            self.register_buffer(\"epsilon_bias\", z)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = math.sqrt(3 / self.in_features)\n",
    "        self.weight.data.uniform_(-std, std)\n",
    "        self.bias.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.epsilon_weight.normal_()\n",
    "        bias = self.bias\n",
    "        if bias is not None:\n",
    "            self.epsilon_bias.normal_()\n",
    "            bias = bias + self.sigma_bias * \\\n",
    "                   self.epsilon_bias.data\n",
    "        v = self.sigma_weight * self.epsilon_weight.data + self.weight\n",
    "        return F.linear(input, v, bias)\n",
    "    \n",
    "\n",
    "class NoisyFactorizedLinear(nn.Linear):\n",
    "    \"\"\"\n",
    "    NoisyNet layer with factorized gaussian noise. This reduces the number of\n",
    "    random numbers to be sampled (so less computationally expensive). There are \n",
    "    two random vectors. One with the size of the input, and the other with the \n",
    "    size of the output. A random matrix is create by calculating the outer \n",
    "    product of the two vectors.\n",
    "    \n",
    "    'register_buffer' is used to create tensors in the network that are not\n",
    "    updated during back-propogation. They are used to create normal \n",
    "    distributions to add noise (multiplied by sigma which is a paramater in the\n",
    "    network).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features,\n",
    "                 sigma_zero=0.4, bias=True):\n",
    "        super(NoisyFactorizedLinear, self).__init__(\n",
    "            in_features, out_features, bias=bias)\n",
    "        sigma_init = sigma_zero / math.sqrt(in_features)\n",
    "        w = torch.full((out_features, in_features), sigma_init)\n",
    "        self.sigma_weight = nn.Parameter(w)\n",
    "        z1 = torch.zeros(1, in_features)\n",
    "        self.register_buffer(\"epsilon_input\", z1)\n",
    "        z2 = torch.zeros(out_features, 1)\n",
    "        self.register_buffer(\"epsilon_output\", z2)\n",
    "        if bias:\n",
    "            w = torch.full((out_features,), sigma_init)\n",
    "            self.sigma_bias = nn.Parameter(w)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.epsilon_input.normal_()\n",
    "        self.epsilon_output.normal_()\n",
    "\n",
    "        func = lambda x: torch.sign(x) * torch.sqrt(torch.abs(x))\n",
    "        eps_in = func(self.epsilon_input.data)\n",
    "        eps_out = func(self.epsilon_output.data)\n",
    "\n",
    "        bias = self.bias\n",
    "        if bias is not None:\n",
    "            bias = bias + self.sigma_bias * eps_out.t()\n",
    "        noise_v = torch.mul(eps_in, eps_out)\n",
    "        v = self.weight + self.sigma_weight * noise_v\n",
    "        return F.linear(input, v, bias)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    \"\"\"Deep Q Network. Udes for both policy (action) and target (Q) networks.\"\"\"\n",
    "\n",
    "    def __init__(self, observation_space, action_space, neurons_per_layer=48):\n",
    "        \"\"\"Constructor method. Set up neural nets.\"\"\"\n",
    "\n",
    "        # Set starting exploration rate\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "        \n",
    "        # Set up action space (choice of possible actions)\n",
    "        self.action_space = action_space\n",
    "              \n",
    "        \n",
    "        # First layerswill be common to both Advantage and value\n",
    "        super(DQN, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Linear(observation_space, neurons_per_layer),\n",
    "            nn.ReLU()            \n",
    "            )\n",
    "        \n",
    "        # Advantage has same number of outputs as the action space\n",
    "        self.advantage = nn.Sequential(\n",
    "            NoisyFactorizedLinear(neurons_per_layer, neurons_per_layer),\n",
    "            nn.ReLU(),\n",
    "            NoisyFactorizedLinear(neurons_per_layer, action_space)\n",
    "            )\n",
    "        \n",
    "        # State value has only one output (one value per state)\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(neurons_per_layer, neurons_per_layer),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(neurons_per_layer, 1)\n",
    "            )        \n",
    "        \n",
    "    def act(self, state):\n",
    "        \"\"\"Act either randomly or by redicting action that gives max Q\"\"\"\n",
    "        \n",
    "        # Act randomly if random number < exploration rate\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action = random.randrange(self.action_space)\n",
    "            \n",
    "        else:\n",
    "            # Otherwise get predicted Q values of actions\n",
    "            q_values = self.forward(torch.FloatTensor(state))\n",
    "            # Get index of action with best Q\n",
    "            action = np.argmax(q_values.detach().numpy()[0])\n",
    "        \n",
    "        return  action\n",
    "        \n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        advantage = self.advantage(x)\n",
    "        value = self.value(x)\n",
    "        action_q = value + advantage - advantage.mean()\n",
    "        return action_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                    4 Define policy net training function                     #\n",
    "################################################################################\n",
    "\n",
    "def optimize(policy_net, target_net, memory):\n",
    "    \"\"\"\n",
    "    Update  model by sampling from memory.\n",
    "    Uses policy network to predict best action (best Q).\n",
    "    Uses target network to provide target of Q for the selected next action.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Do not try to train model if memory is less than reqired batch size\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return    \n",
    " \n",
    "    # Reduce exploration rate (exploration rate is stored in policy net)\n",
    "    policy_net.exploration_rate *= EXPLORATION_DECAY\n",
    "    policy_net.exploration_rate = max(EXPLORATION_MIN, \n",
    "                                      policy_net.exploration_rate)\n",
    "    # Sample a random batch from memory\n",
    "    batch = random.sample(memory, BATCH_SIZE)\n",
    "    for state, action, reward, state_next, terminal in batch:\n",
    "        \n",
    "        state_action_values = policy_net(torch.FloatTensor(state))\n",
    "        \n",
    "        # Get target Q for policy net update\n",
    "       \n",
    "        if not terminal:\n",
    "            # For non-terminal actions get Q from policy net\n",
    "            expected_state_action_values = policy_net(torch.FloatTensor(state))\n",
    "            # Detach next state values from gradients to prevent updates\n",
    "            expected_state_action_values = expected_state_action_values.detach()\n",
    "            # Get next state action with best Q from the policy net (double DQN)\n",
    "            policy_next_state_values = policy_net(torch.FloatTensor(state_next))\n",
    "            policy_next_state_values = policy_next_state_values.detach()\n",
    "            best_action = np.argmax(policy_next_state_values[0].numpy())\n",
    "            # Get target net next state\n",
    "            next_state_action_values = target_net(torch.FloatTensor(state_next))\n",
    "            # Use detach again to prevent target net gradients being updated\n",
    "            next_state_action_values = next_state_action_values.detach()\n",
    "            best_next_q = next_state_action_values[0][best_action].numpy()\n",
    "            updated_q = reward + (GAMMA * best_next_q)      \n",
    "            expected_state_action_values[0][action] = updated_q\n",
    "        else:\n",
    "            # For termal actions Q = reward (-1)\n",
    "            expected_state_action_values = policy_net(torch.FloatTensor(state))\n",
    "            # Detach values from gradients to prevent gradient update\n",
    "            expected_state_action_values = expected_state_action_values.detach()\n",
    "            # Set Q for all actions to reward (-1)\n",
    "            expected_state_action_values[0] = reward\n",
    " \n",
    "        # Set network to training mode\n",
    "        policy_net.train()\n",
    "        # Reset net gradients\n",
    "        policy_net.optimizer.zero_grad()  \n",
    "        # calculate loss\n",
    "        loss_v = nn.MSELoss()(state_action_values, expected_state_action_values)\n",
    "        # Backpropogate loss\n",
    "        loss_v.backward()\n",
    "        # Update network gradients\n",
    "        policy_net.optimizer.step()  \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                            5 Define memory class                             #\n",
    "################################################################################\n",
    "\n",
    "class Memory():\n",
    "    \"\"\"\n",
    "    Replay memory used to train model.\n",
    "    Limited length memory (using deque, double ended queue from collections).\n",
    "      - When memory full deque replaces oldest data with newest.\n",
    "    Holds, state, action, reward, next state, and episode done.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor method to initialise replay memory\"\"\"\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"state/action/reward/next_state/done\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                       6  Define results plotting function                    #\n",
    "################################################################################\n",
    "\n",
    "def plot_results(run, exploration, score, run_details):\n",
    "    \"\"\"Plot and report results at end of run\"\"\"\n",
    "    \n",
    "    # Get beds and patients from run_detals DataFrame\n",
    "    beds = run_details['beds']\n",
    "    patients = run_details['patients']    \n",
    "    \n",
    "    # Set up chart (ax1 and ax2 share x-axis to combine two plots on one graph)\n",
    "    fig = plt.figure(figsize=(9,5))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot results\n",
    "    average_rewards = np.array(score)/SIM_DURATION\n",
    "    ax1.plot(run, exploration, label='exploration', color='g')\n",
    "    ax2.plot(run, average_rewards, label='average reward', color='r')\n",
    "    \n",
    "    # Set axes\n",
    "    ax1.set_xlabel('run')\n",
    "    ax1.set_ylabel('exploration', color='g')\n",
    "    ax2.set_ylabel('average reward', color='r')\n",
    "    \n",
    "    # Show last run tracker of beds and patients\n",
    "\n",
    "    ax3 = fig.add_subplot(122)\n",
    "    day = np.arange(len(beds))*TIME_STEP\n",
    "    ax3.plot(day, beds, label='beds', color='g')\n",
    "    ax3.plot(day, patients, label='patients', color='r')\n",
    "    \n",
    "    # Set axes\n",
    "    ax3.set_xlabel('day')\n",
    "    ax3.set_ylabel('beds/patients')\n",
    "    ax3.set_ylim(0)\n",
    "    ax3.legend()\n",
    "    ax3.grid()\n",
    "    # Show\n",
    "    \n",
    "    plt.tight_layout(pad=2)\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate summary results\n",
    "    results = pd.Series()\n",
    "    beds = np.array(beds)\n",
    "    patients = np.array(patients)\n",
    "    results['days under capacity'] = np.sum(patients > beds)\n",
    "    results['days over capacity'] = np.sum(beds > patients)\n",
    "    results['average patients'] = np.round(np.mean(patients), 0)\n",
    "    results['average beds'] = np.round(np.mean(beds), 0)\n",
    "    results['% occupancy'] = np.round((patients.sum() / beds.sum() * 100), 1)\n",
    "    print (results);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                                 7 Main program                               #\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def hosp_bed_management():\n",
    "    \"\"\"Main program loop\"\"\"\n",
    "    \n",
    "    ############################################################################\n",
    "    #                          8 Set up environment                            #\n",
    "    ############################################################################\n",
    "        \n",
    "    # Set up game environemnt\n",
    "    sim = HospGym(sim_duration=SIM_DURATION, time_step=TIME_STEP)\n",
    "\n",
    "    # Get number of observations returned for state\n",
    "    observation_space = sim.observation_size\n",
    "    \n",
    "    # Get number of actions possible\n",
    "    action_space = sim.action_size\n",
    "    \n",
    "    ############################################################################\n",
    "    #                    9 Set up policy and target nets                       #\n",
    "    ############################################################################\n",
    "    \n",
    "    # Set up policy and target neural nets\n",
    "    policy_net = DQN(observation_space, action_space)\n",
    "    target_net = DQN(observation_space, action_space)\n",
    "    \n",
    "    # Set loss function and optimizer\n",
    "    policy_net.optimizer = optim.Adam(\n",
    "            params=policy_net.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Copy weights from policy_net to target\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "    # Set target net to eval rather than training mode\n",
    "    # We do not train target net - ot is copied from policy net at intervals\n",
    "    target_net.eval()\n",
    "    \n",
    "    ############################################################################\n",
    "    #                            10 Set up memory                              #\n",
    "    ############################################################################\n",
    "        \n",
    "    # Set up memomry\n",
    "    memory = Memory()\n",
    "    \n",
    "    ############################################################################\n",
    "    #                     11 Set up + start training loop                      #\n",
    "    ############################################################################\n",
    "    \n",
    "    # Set up run counter and learning loop    \n",
    "    run = 0\n",
    "    all_steps = 0\n",
    "    continue_learning = True\n",
    "    \n",
    "    # Set up list for results\n",
    "    results_run = []\n",
    "    results_exploration = []\n",
    "    results_score = []\n",
    "    \n",
    "    # Continue repeating games (episodes) until target complete\n",
    "    while continue_learning:\n",
    "        \n",
    "        ########################################################################\n",
    "        #                           12 Play episode                            #\n",
    "        ########################################################################\n",
    "        \n",
    "        # Increment run (episode) counter\n",
    "        run += 1\n",
    "        \n",
    "        ########################################################################\n",
    "        #                             13 Reset game                            #\n",
    "        ########################################################################\n",
    "        \n",
    "        # Reset game environment and get first state observations\n",
    "        state = sim.reset()\n",
    "        \n",
    "        # Trackers for state\n",
    "        weekday = []\n",
    "        beds = []\n",
    "        patients = []\n",
    "        spare_beds = []\n",
    "        pending_change = []\n",
    "        rewards = [] \n",
    "        \n",
    "        # Reset total reward\n",
    "        total_reward = 0    \n",
    "   \n",
    "        # Reshape state into 2D array with state obsverations as first 'row'\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        \n",
    "        # Continue loop until episode complete\n",
    "        while True:\n",
    "            \n",
    "        ########################################################################\n",
    "        #                       14 Game episode loop                           #\n",
    "        ########################################################################\n",
    "\n",
    "            ####################################################################\n",
    "            #                       15 Get action                              #\n",
    "            ####################################################################\n",
    "            \n",
    "            # Get action to take (use evalulation mode)\n",
    "            policy_net.eval()\n",
    "            action = policy_net.act(state)\n",
    "            \n",
    "            ####################################################################\n",
    "            #                 16 Play action (get S', R, T)                    #\n",
    "            ####################################################################\n",
    "            \n",
    "            # Act\n",
    "            state_next, reward, terminal, info = sim.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Update trackers\n",
    "            weekday.append(state_next[0])\n",
    "            beds.append(state_next[1])\n",
    "            patients.append(state_next[2])\n",
    "            spare_beds.append(state_next[3])\n",
    "            pending_change.append(state_next[4])\n",
    "            rewards.append(reward)\n",
    "                                                          \n",
    "            # Reshape state into 2D array with state obsverations as first 'row'\n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            \n",
    "            # Update display if needed\n",
    "            if DISPLAY_ON_SCREEN:\n",
    "                sim.render()\n",
    "            \n",
    "            ####################################################################\n",
    "            #                  17 Add S/A/R/S/T to memory                      #\n",
    "            ####################################################################\n",
    "            \n",
    "            # Record state, action, reward, new state & terminal\n",
    "            memory.remember(state, action, reward, state_next, terminal)\n",
    "            \n",
    "            # Update state\n",
    "            state = state_next\n",
    "            \n",
    "            ####################################################################\n",
    "            #                  18 Check for end of episode                     #\n",
    "            ####################################################################\n",
    "            \n",
    "            # Actions to take if end of game episode\n",
    "            if terminal:\n",
    "                # Get exploration rate\n",
    "                exploration = policy_net.exploration_rate\n",
    "                # Clear print row content\n",
    "                clear_row = '\\r' + ' '*79 + '\\r'\n",
    "                print (clear_row, end ='')\n",
    "                print (f'Run: {run}, ', end='')\n",
    "                print (f'Exploration: {exploration: .3f}, ', end='')\n",
    "                average_reward = total_reward/SIM_DURATION\n",
    "                print (f'Average reward: {average_reward:4.1f}', end='')\n",
    "                \n",
    "                # Add to results lists\n",
    "                results_run.append(run)\n",
    "                results_exploration.append(exploration)\n",
    "                results_score.append(total_reward)\n",
    "                \n",
    "                ################################################################\n",
    "                #             18b Check for end of learning                    #\n",
    "                ################################################################\n",
    "                \n",
    "                if run == TRAINING_EPISODES:\n",
    "                    continue_learning = False\n",
    "                \n",
    "                # End episode loop\n",
    "                break\n",
    "            \n",
    "            \n",
    "            ####################################################################\n",
    "            #                        19 Update policy net                      #\n",
    "            ####################################################################\n",
    "            \n",
    "            # Avoid training model if memory is not of sufficient length\n",
    "            if len(memory.memory) > REPLAY_START_SIZE:\n",
    "        \n",
    "                # Update policy net\n",
    "                optimize(policy_net, target_net, memory.memory)\n",
    "\n",
    "                ################################################################\n",
    "                #             20 Update target net periodically                #\n",
    "                ################################################################\n",
    "                \n",
    "                # Use load_state_dict method to copy weights from policy net\n",
    "                if all_steps % SYNC_TARGET_STEPS == 0:\n",
    "                    target_net.load_state_dict(policy_net.state_dict())\n",
    "                \n",
    "    ############################################################################\n",
    "    #                      21 Learning complete - plot results                 #\n",
    "    ############################################################################\n",
    "\n",
    "    # Add last run to DataFrame. summarise, and return\n",
    "    run_details = pd.DataFrame()\n",
    "    run_details['weekday'] = weekday \n",
    "    run_details['beds'] = beds\n",
    "    run_details['patients'] = patients\n",
    "    run_details['spare_beds'] = spare_beds\n",
    "    run_details['pending_change'] = pending_change\n",
    "    run_details['reward'] = rewards    \n",
    "        \n",
    "    # Target reached. Plot results\n",
    "    plot_results(\n",
    "        results_run, results_exploration, results_score, run_details)\n",
    "    \n",
    "    return run_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 250, Exploration:  0.000, Average reward: -36.3                           "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days under capacity    149.0\n",
      "days over capacity     212.0\n",
      "average patients       497.0\n",
      "average beds           511.0\n",
      "% occupancy             97.3\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Run model and return last run results by day\n",
    "last_run = hosp_bed_management()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
